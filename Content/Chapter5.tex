\chapter{Πειραματική Αξιολόγηση}
\label{ch:Experimental Evaluation}
Οι διάφορες υλοποιήσεις που πραγματοποιήθηκαν στα πλαίσια της τρέχουσας διπλωματικής εργασίας αξιολογήθηκαν πειραματικά με τη χρήση μετροπρογραμμάτων (benchmarks) τόσο για την επιβεβαίωση της ορθότητας της υλοποίησης, όσο και για τη μέτρηση των επιδόσεων που επιτεύχθηκαν.


\section{Περιγραφή Συστημάτων}
\label{sec:Systems Description}
Η εκτέλεση των πειραμάτων έγινε σε δύο υπολογιστικά συστήματα τα οποία αντιπροσωπεύουν συνήθεις αλλά διαφορετικές αρχιτεκτονικές οργανώσεις NUMA. Τα χαρακτηριστικά των συστημάτων αυτών, τόσο από άποψη υλικού, όσο και από άποψη λογισμικού, φαίνονται στους Πίνακες \ref{tab:exp-systems-hardware} και \ref{tab:exp-systems-software}. Η αρχιτεκτονική των επεξεργαστών όλων των συστημάτων είναι η \textit{x86-64} ενώ το μέγεθος μιας γραμμής της κρυφής μνήμης είναι 64 bytes.

Οι μεταφραστές οι οποίοι χρησιμοποιήθηκαν για τη συγκριτική αξιολόγηση της δουλειάς μας είναι ο \textit{GNU C Compiler} (GCC), ο \textit{Intel C Compiler} (ICC)\footnote{Εγκαταστάθηκε μέσω των oneAPI Toolkits της Intel\textsuperscript{\textregistered}.} και ο \textit{Clang}. Ο πηγαίος κώδικας του OMPi μεταφράστηκε με τον GCC, ενώ τα απαιτούμενα πακέτα λογισμικού είναι διαθέσιμα στο Παράρτημα \ref{app:OMPi's software requirements}.

\begin{table}
	\centering
		\begin{tabular}{|c||c|c|c|c|c|c|}
		\hline
		Hostname & Proc. Mfr. & NUMA nodes & Sockets & Cores & H/W threads & RAM \\
		\hline \hline
		\texttt{parade} & Intel & 4 & 4 & 64 & 128 & 256 GiB \\
		\hline
		\texttt{paragon} & AMD  & 4 & 2 & 24 & 24 & 16 GiB \\
		\hline
		\end{tabular}
		\caption{Χαρακτηριστικά υλικού των πειραματικών συστημάτων.}
		\label{tab:exp-systems-hardware}
\end{table}

\begin{table}
	\centering
		\begin{tabular}{|c||c|c|c|c|c|c|c|}
		\hline
		Hostname & OS & GCC & ICC & Clang & hwloc & Linux kernel \\
		\hline \hline
		\texttt{parade} & CentOS 8 & \texttt{8.4.1} & \texttt{2021.3.0} & \texttt{11.0.0} & \texttt{2.2.0} & \texttt{4.18.0} \\
		\hline
		\texttt{paragon} & CentOS 8 & \texttt{8.4.1} & \texttt{2021.3.0} & \texttt{11.0.0} & \texttt{2.2.0} & \texttt{4.18.0} \\
		\hline
		\end{tabular}
		\caption{Χαρακτηριστικά λογισμικού των πειραματικών συστημάτων.}
		\label{tab:exp-systems-software}
\end{table}


\subsection{Parade}
Ο Parade είναι ένα σύστημα Dell PowerEdge R840 με τέσσερις κόμβους NUMA. Κάθε κόμβος διαθέτει 64 GiB μνήμης και έναν επεξεργαστή \textit{Intel\textsuperscript{\textregistered} Xeon\textsuperscript{\textregistered} Gold 6130} ο οποίος αποτελείται από 12 πυρήνες και ιεραρχία κρυφών μνημών τριών επιπέδων (L1i \& L1d, L2, L3). Τα επίπεδα ένα και δύο των κρυφών μνημών είναι κοινά ανά πυρήνα, ενώ το επίπεδο τρία είναι κοινό για όλους τους πυρήνες του επεξεργαστή. Επίσης, κάθε πυρήνας περιέχει δύο H/W threads. Η σχηματική αναπαράσταση της τοπολογίας του είχε δοθεί στο Σχήμα \ref{fig:parade-topo}.

\subsection{Paragon}
Ο Paragon είναι ένα σύστημα με δύο επεξεργαστές \textit{AMD Opteron\textsuperscript{\texttrademark} Processor 6166 HE}, καθένας από τους οποίους περιλαμβάνει δύο κόμβους NUMA. Κάθε κόμβος διαθέτει 6 πυρήνες του ενός H/W thread και ιεραρχία κρυφής μνήμης τριών επιπέδων αντίστοιχη με τους κόμβους του συστήματος Parade που είδαμε προηγουμένως. Η σχηματική αναπαράσταση της τοπολογίας του φαίνεται στο Σχήμα \ref{fig:paragon-topo}.

Ο λόγος που κάθε επεξεργαστής περιλαμβάνει δύο κόμβους είναι επειδή ουσιαστικά αποτελείται από δύο κυκλώματα επεξεργαστών (dies) των έξι πυρήνων το καθένα, τα οποία συνδέονται μεταξύ τους με ένα δίκτυο διασύνδεσης χαμηλής καθυστέρησης και υψηλού εύρους ζώνης που ονομάζεται HyperTransport, με σκοπό να δημιουργηθεί ένα ολοκληρωμένο κύκλωμα επεξεργαστή με 12 πυρήνες \cite{conway2010cache}. Κάθε die μπορεί να επικοινωνήσει απευθείας με τη μνήμη\footnote{Επειδή περιλαμβάνει ελεγκτή μνήμης (memory controller).}, οπότε λόγω της ύπαρξης δικτύου διασύνδεσης μεταξύ των dies, κάθε επεξεργαστής μπορεί να θεωρηθεί ως ένα σύστημα NUMA δύο κόμβων.


\begin{figure}[t]
	\centering
	\includegraphics[width=0.8\textwidth]{Figures/paragon-topo.pdf}
	\linebreak
	\caption{Η τοπολογία του συστήματος Paragon.}
	\label{fig:paragon-topo}
\end{figure}


\section{Τοπολογία}
Η υλοποίηση των OpenMP places και OpenMP processor binding policies ελέγχθηκε για την ορθότητά της, δηλαδή  για το αν ικανοποιεί πλήρως τις προδιαγραφές του OpenMP, τόσο με ιδιόχειρα, όσο και με έτοιμα προγράμματα.   Τα έτοιμα προγράμματα ήταν μέρος ενός συνόλου προγραμμάτων ελέγχου ορθότητας τα οποία παρέχονται από τη βιβλιοθήκη \textit{GNU Offloading and Multi Processing Runtime Library} (libgomp) η οποία μεταξύ άλλων, υλοποιεί και τη διεπαφή προγραμματισμού εφαρμογών OpenMP που χρησιμοποιεί ο GCC.


\section{Barrier}
\label{sec:exp-barrier}
Η υλοποίηση του tree barrier ελέγχθηκε για την ορθότητά της με προγράμματα ελέγχου από τη βιβλιοθήκη libgomp και την \textit{OpenMP Validation Suite V 3.0} \cite{wang2012openmp, ompvalsuite3}. Ο λόγος όμως που αναπτύχθηκε ο tree barrier ήταν οι μειωμένες επιδόσεις του υπάρχοντα barrier του OMPi σε συστήματα NUMA, οπότε αφού εξασφαλίστηκε η ορθότητα της υλοποίησης, εστιάσαμε στο ζήτημα των επιδόσεων με τη χρήση μετροπρογραμμάτων.

Η \textit{EPCC OpenMP micro-benchmark suite} \cite{bull1999measuring} είναι ένα σύνολο μετροπρογραμμάτων (micro-benchmarks) τα οποία μετράνε το κόστος σε χρόνο (overhead) που απαιτείται για τη διεκπεραίωση λειτουργιών όπως ο συγχρονισμός (π.χ. barrier, κλειδαριές), η \textit{χρονοδρομολόγηση βρόχου} (loop scheduling) και οι πράξεις πινάκων. Η πιο πρόσφατη έκδοση (3.1) υποστηρίζει μέχρι και τις λειτουργίες που προδιαγράφει το OpenMP 3.0.

Τα πειράματα που πραγματοποιήθηκαν επικεντρώθηκαν στη μέτρηση του overhead του barrier, όσο το πλήθος των κόμβων NUMA που χρησιμοποιούνται αυξάνεται. Πιο συγκεκριμένα, ανατίθεται ένα νήμα σε κάθε core ή H/W thread του κόμβου, ενώ πραγματοποιούνται εκτελέσεις με 1 έως $N$ κόμβους, όπου $N$ το πλήθος των διαθέσιμων κόμβων του συστήματος.
% Η ανάθεση των νημάτων επιτυγχάνεται θέτοντας \texttt{OMP\_PROC\_BIND="close"}, \texttt{OMP\_PLACES="cores"} ή \texttt{OMP\_PLACES="threads"} και \texttt{OMP\_NUM\_THREADS=$N$}, όπου $N$ το πλήθος των νημάτων ανά κόμβο.
 Με αυτό τον τρόπο ελέγχουμε κατά πόσο η εκάστοτε υλοποίηση barrier είναι κλιμακώσιμη. Οι υλοποιήσεις που συγκρίθηκαν είναι αυτές των μεταφραστών OMPi (κλασική και tree barrier), GCC, ICC και Clang.


\subsection{Parade}
Στο Σχήμα \ref{fig:bo-parade-default-places} φαίνεται το overhead του barrier κάθε μεταφραστή όταν χρησιμοποιούνται 1 έως 4 κόμβοι και ένα νήμα ανά core ή H/W thread αντίστοιχα. Αυτό που παρατηρούμε, είναι ότι όταν \texttt{OMP\_PLACES="cores"}, για ένα κόμβο ο OMPi έχει το μικρότερο overhead, το οποίο όμως αυξάνει κατά πολύ για περισσότερους κόμβους. Στην περίπτωση που \texttt{OMP\_PLACES="threads"}, ο OMPi έχει εκθετική αύξηση του overhead για 2 ή περισσότερους κόμβους. Ο tree barrier και στις δύο περιπτώσεις έχει σαφώς καλύτερες επιδόσεις σε σχέση με τον κλασικό barrier του OMPi, ενώ το overhead του αυξάνεται με αρκετά μικρό ρυθμό. Εξαίρεση αποτελεί η περίπτωση που χρησιμοποιείται ένας μόνο κόμβος, κατά την οποία o tree barrier είναι λίγο πιο αργός από τον κλασικό barrier. % Για καλύτερη κατανόηση δείτε το Σχήμα \ref{fig:bo-parade-ompionly}.

%\begin{figure}[t]
%	\centering
%	\includegraphics[width=0.7\textwidth]{Figures/epcc_20210823_175412/default-places_cores_close.pdf}
%	\linebreak
%	\caption{Barrier overhead στον Parade: OMP\_PLACES=cores.}
%	\label{fig:bo-parade-cores}
%\end{figure}
%
%\begin{figure}[t]
%	\centering
%	\includegraphics[width=0.7\textwidth]{Figures/epcc_20210823_175412/default-places_threads_close.pdf}
%	\linebreak
%	\caption{Barrier overhead στον Parade: OMP\_PLACES=threads.}
%	\label{fig:bo-parade-threads}
%\end{figure}

\begin{figure}
    \centering
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Figures/epcc_20210823_175412/default-places_cores_close.pdf}
		\texttt{OMP\_PLACES=cores}
    \end{minipage}\hfill
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Figures/epcc_20210823_175412/default-places_threads_close.pdf}
        \texttt{OMP\_PLACES=threads}
    \end{minipage}
    \caption{Barrier overhead στον Parade (Default places).}
    \label{fig:bo-parade-default-places}
\end{figure}

%\begin{figure}
%    \centering
%    \begin{minipage}{0.5\textwidth}
%        \centering
%        \includegraphics[width=1\textwidth]{Figures/epcc_20210823_175412/ompi_default-places_cores_close.pdf}
%		\texttt{OMP\_PLACES=cores}
%    \end{minipage}\hfill
%    \begin{minipage}{0.5\textwidth}
%        \centering
%        \includegraphics[width=1\textwidth]{Figures/epcc_20210823_175412/ompi_default-places_threads_close.pdf}
%        \texttt{OMP\_PLACES=threads}
%    \end{minipage}
%    \caption{Barrier overhead στον Parade για τους barriers του OMPi (Default places).}
%    \label{fig:bo-parade-ompionly}
%\end{figure}

Η σύγκριση που πραγματοποιήθηκε, ναι μεν είναι σωστή από την πλευρά του χρήστη καθώς χρησιμοποιείται το ίδιο abstract name για τον καθορισμό των places, όμως ο κάθε μεταφραστής μετασχηματίζει με διαφορετικό τρόπο το abstract name σε σύνολα από αναγνωριστικά επεξεργαστών. Για παράδειγμα, όταν \texttt{OMP\_PLACES=cores} o GCC τοποθετεί στο place partition με κυκλικό τρόπο (round-robin) ένα core ανά κόμβο. Συνεπώς, αν ο χρήστης επιλέξει ως processor binding policy την \texttt{close}, νήματα που θα τοποθετηθούν σε γειτονικά places, θα καταλήξουν σε διαφορετικούς κόμβους NUMA.

Λόγω της ουσιαστικής διαφοράς στο place partition που χρησιμοποιεί το σύστημα χρόνου εκτέλεσης του κάθε μεταφραστή, πραγματοποιήσαμε επιπλέον μετρήσεις κατά τις οποίες ορίσαμε την τιμή της μεταβλητής \texttt{OMP\_PLACES} χειροκίνητα, βάσει του πώς δημιουργεί το place partition ο κάθε μεταφραστής. Οι μεταφραστές ICC και Clang ορίζουν με τον ίδιο τρόπο το place partition, οπότε προέκυψαν οι τρεις ακόλουθοι τρόποι ορισμού του:
\begin{itemize}
	\item OMPi places: \texttt{OMP\_PLACES="ompi-cores"} και \texttt{OMP\_PLACES="ompi-threads"}.
	\item GCC places: \texttt{OMP\_PLACES="gcc-cores"} και \texttt{OMP\_PLACES="gcc-threads"}.
	\item Clang/ICC places: \texttt{OMP\_PLACES="clang-cores"} και \texttt{OMP\_PLACES="clang-threads"}.
\end{itemize}

Στα Σχήματα \ref{fig:bo-parade-ompi-places}, \ref{fig:bo-parade-gcc-places} και \ref{fig:bo-parade-clang-places} μπορείτε να δείτε τις μετρήσεις οι οποίες πάρθηκαν με όλους τους μεταφραστές να χρησιμοποιούν το ίδιο place partition. Σε όλες τις περιπτώσεις που χρησιμοποιούνται πολλαπλοί κόμβοι είναι εμφανής η επίτευξη καλύτερης επίδοσης του tree barrier σε σχέση με τον κλασικό barrier του OMPi. Το overhead όταν χρησιμοποιούνται δύο κόμβοι είναι σαφώς πιο αυξημένο σε σχέση με όταν χρησιμοποιείται ένας κόμβος, φαινόμενο πλήρως δικαιολογημένο καθώς στην τελευταία περίπτωση δεν πραγματοποιούνται απομακρυσμένες προσβάσεις μνήμης. Όσο το πλήθος των κόμβων αυξάνεται σε τιμές μεγαλύτερες του δύο, παρατηρούμε ότι η αύξηση του overhead είναι πολύ μικρή. %s Το γεγονός αυτό επιβεβαιώνει την κλιμακωσιμότητα του νέου barrier.

Σε μερικά σχήματα είναι ορατές μη αναμενόμενες συμπεριφορές από τον ICC, όπως για παράδειγμα στο Σχήμα \ref{fig:bo-parade-ompi-places} όπου διακρίνεται ένα πολύ μεγαλύτερο overhead για δύο κόμβους σε σχέση με τους τρεις κόμβους. Αυτό το φαινόμενο παρατηρήθηκε στην τρέχουσα έκδοση του ICC μετά από την πιο πρόσφατη αναβάθμιση που πραγματοποιήθηκε ώστε οι εκδόσεις των πακέτων λογισμικού να ταυτίζονται με αυτές του συστήματος Paragon και άρα να μην οδηγηθούμε σε εσφαλμένα συμπεράσματα λόγω διαφορών ανάμεσα στις εκδόσεις.

\begin{figure}
    \centering
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Figures/epcc_20210823_175412/ompi-places_cores_close.pdf}
		\texttt{OMP\_PLACES=ompi-cores}
    \end{minipage}\hfill
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Figures/epcc_20210823_175412/ompi-places_threads_close.pdf}
        \texttt{OMP\_PLACES=ompi-threads}
    \end{minipage}
    \caption{Barrier overhead στον Parade (OMPi places).}
    \label{fig:bo-parade-ompi-places}
\end{figure}

\begin{figure}
    \centering
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Figures/epcc_20210823_175412/gcc-places_cores_close.pdf}
		\texttt{OMP\_PLACES=gcc-cores}
    \end{minipage}\hfill
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Figures/epcc_20210823_175412/gcc-places_threads_close.pdf}
        \texttt{OMP\_PLACES=gcc-threads}
    \end{minipage}
    \caption{Barrier overhead στον Parade (GCC places).}
    \label{fig:bo-parade-gcc-places}
\end{figure}

\begin{figure}
    \centering
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Figures/epcc_20210823_175412/clang-places_cores_close.pdf}
		\texttt{OMP\_PLACES=clang-cores}
    \end{minipage}\hfill
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Figures/epcc_20210823_175412/clang-places_threads_close.pdf}
        \texttt{OMP\_PLACES=clang-threads}
    \end{minipage}
    \caption{Barrier overhead στον Parade (Clang/ICC places).}
    \label{fig:bo-parade-clang-places}
\end{figure}


\subsection{Paragon}
Στα Σχήματα \ref{fig:bo-paragon-default-places} και \ref{fig:bo-paragon-default-places-ompionly} φαίνονται τα αποτελέσματα των μετρήσεων που πραγματοποιήθηκαν στον Paragon. Επειδή κάθε core διαθέτει μόνο ένα H/W thread, τα abstract names \texttt{threads} και \texttt{cores} έχουν το ίδιο αποτέλεσμα. Εξαίρεση αποτελούν οι ICC και Clang οι οποίοι εσφαλμένα θεωρούν ότι κάθε επεξεργαστής διαθέτει ένα μόνο core αντί για δώδεκα, γεγονός που θεωρήθηκε ως σφάλμα (bug) και αγνοήθηκε.

\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Figures/paragon_epcc_20210825_132109/default-places_threads_close.pdf}
		\caption{Barrier overhead στον Paragon.}
		\label{fig:bo-paragon-default-places}
    \end{minipage}\hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{Figures/paragon_epcc_20210825_132109/ompi_default-places_threads_close.pdf}
        \caption{Barrier overhead στον Paragon για τους barriers του OMPi.}
        \label{fig:bo-paragon-default-places-ompionly}
    \end{minipage}
\end{figure}


%
%\begin{figure}[t]
%	\centering
%	\includegraphics[width=0.7\textwidth]{Figures/paragon_epcc_20210825_132109/default-places_threads_close.pdf}
%	\linebreak
%	\caption{Barrier overhead στον Paragon: OMP\_PLACES=threads.}
%	\label{fig:bo-paragon-threads}
%\end{figure}
%
%\begin{figure}[t]
%	\centering
%	\includegraphics[width=0.7\textwidth]{Figures/paragon_epcc_20210825_132109/ompi_default-places_threads_close.pdf}
%	\linebreak
%	\caption{Barrier overhead στον Paragon για τους barriers του OMPi.}
%	\label{fig:bo-paragon-ompionly}
%\end{figure}

Από τις μετρήσεις στον Paragon παρατηρούμε ότι τα overheads των OMPi, GCC και ICC αυξάνουν σχεδόν γραμμικά και συγκλίνουν για πλήθος τεσσάρων κόμβων. Ο Clang φαίνεται ότι κλιμακώνει καλύτερα για τρεις και τέσσερις κόμβους από τους OMPi, GCC και ICC, αλλά όχι το ίδιο αποδοτικά όπως συνέβαινε στον Parade. Ο OMPi tree barrier επιδεικνύει την καλύτερη επίδοση για τρεις και τέσσερις κόμβους, με το overhead να αυξάνει με πολύ μικρό ρυθμό όσο αυξάνεται το πλήθος των κόμβων, φαινόμενο που παρατηρήθηκε και στον Parade. Επιπλέον, παρατηρούμε ο tree barrier έχει οριακά μεγαλύτερο overhead σε σχέση με τον κλασικό barrier του OMPi, όχι μόνο για ένα κόμβο αλλά και για δύο. Κάτι τέτοιο πιθανώς συμβαίνει καθώς οι δύο κόμβοι ανήκουν στο ίδιο ενσωματωμένο κύκλωμα επεξεργαστή.


%\subsubsection{Σύνοψη συμπερασμάτων}
%Ο νέος αλγόριθμος tree barrier που υλοποιήθηκε βελτίωσε σημαντικά το κόστος που απαιτεί ο συγχρονισμός των νημάτων όταν χρησιμοποιούνται δύο ή περισσότεροι κόμβοι NUMA, γεγονός που καθιστά εφικτή και αποδοτική την κλιμακωσιμότητα του μεταφραστή OMPi σε συστήματα NUMA πάρα πολλών πυρήνων.

